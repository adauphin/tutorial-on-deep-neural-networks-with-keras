{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ecQT698A6s2P",
        "-7tzOxTH6zaK",
        "FOnxNEMr7KDV",
        "6kD6vQlV78e7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adauphin/tutorial-on-deep-neural-networks-with-keras/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rt4gwaPR6hyw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Tutorial on deep neural networks and deep convolutionnal neural networks</h1>\n",
        "\n",
        "---\n",
        "\n",
        "**Alexandre Dauphin**"
      ]
    },
    {
      "metadata": {
        "id": "ecQT698A6s2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ]
    },
    {
      "metadata": {
        "id": "9q_2DucX6dai",
        "colab_type": "code",
        "outputId": "ddb9b2f1-5358-4138-a351-2f7a8d3e422e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import numpy and matplotlib\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#import keras and tools from keras to generate neural networks and convolutionnal neural networks\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input,Dense,Conv2D,MaxPooling2D,Flatten, Activation, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# import the dataset\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# scikit learn\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#miscellaneous\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-7tzOxTH6zaK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Link the colab file to your google drive\n",
        "\n",
        "---\n",
        "\n",
        "By executing the next cell, we will be able to access and write data on the google drive"
      ]
    },
    {
      "metadata": {
        "id": "RJSbbxrp67nH",
        "colab_type": "code",
        "outputId": "a0accb33-e316-46a9-aced-f1e601c5851b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "#link the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOnxNEMr7KDV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset\n",
        "---\n",
        "We now import the MNIST hanwritten digits and explore it. We first load the data"
      ]
    },
    {
      "metadata": {
        "id": "XbU7vlEj7MbU",
        "colab_type": "code",
        "outputId": "bba7dae2-2dbb-4e98-edf9-5a9f2aeabe94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "n_classes=10 #number of classes in the MNIST dataset, numbers from 0 to 9\n",
        "\n",
        "(x_train,y_train1), (x_test,y_test1) = mnist.load_data()\n",
        "x_train1 = x_train.astype('float32') / 255.\n",
        "x_test1 = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train1, n_classes) # this keras funtion transforms the labels into vectors. For example, 2 becomes [0,0,1,0,0,0,0,0,0,0]\n",
        "y_test = np_utils.to_categorical(y_test1, n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCL7zfwq7g0t",
        "colab_type": "code",
        "outputId": "8ad6b712-0804-4983-8aa3-05ac1572bb25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "# We take 12 examples in the training set\n",
        "nexample=12\n",
        "mask=np.random.randint(x_train.shape[0],size=nexample)\n",
        "\n",
        "fig,axes=plt.subplots(nrows=1,ncols=nexample,figsize=(20,20))\n",
        "\n",
        "i=-1\n",
        "for ax in axes.flat:\n",
        "  i=i+1\n",
        "  nn=mask[i]\n",
        "  ax.imshow(x_train1[nn,:,:],cmap='gray_r')\n",
        "  ax.set_title('label: '+str(y_train1[nn]))\n",
        "  ax.axis('off')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHwAAAB8CAYAAAAbx6c8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6kD6vQlV78e7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep neural networks (Fully connected)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5CZ1B1Pplpne",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now construct our first neural network. The input of the neural network is a vector of 28X28=784 elements. We then make the data pass through 3 hidden fully connected neural networks with repectively 200, 64 and 10 neurons. We finally perform the classification in the last layer with a softmax function. \n",
        "\n",
        "Then, we compile model the model and we specify the Cost function (here cross entropy), the optimizer (adam, an elaborated version of the stochastic gradient descent), and the metrics.\n",
        "\n",
        "\n",
        "Your goal is now to construct the neural network architecture. We will do it in keras\n",
        "\n",
        "https://keras.io/#getting-started-30-seconds-to-keras"
      ]
    },
    {
      "metadata": {
        "id": "hpyJlkNs-gkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gX4Ol-Aq79Et",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "bc59a557-e124-41fc-834c-4f95e9b71cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=200, input_dim=784,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                12864     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 170,514\n",
            "Trainable params: 170,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oYBIxuiW9fL6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the model. To this end, we use the function model.fit(). The latter allows one to choose the batch size and the division between training and validation set.\n",
        "We put some checkpoints that will save the weigths of the neural network after each epoch. We also save the history after the training to have access to the learning curves (loss function and accuracy)"
      ]
    },
    {
      "metadata": {
        "id": "EzEPi3s_vnPE",
        "colab_type": "code",
        "outputId": "7c36cdc9-175f-4508-dd29-15fef395be6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1068
        }
      },
      "cell_type": "code",
      "source": [
        "# This line should be put if the model has been previously trained\n",
        "#model.load_weights('drive/My Drive/weights.best.hdf5')\n",
        "# checkpoint\n",
        "filepath=\"drive/My Drive/weights_fnn.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "\n",
        "history=model.fit(x_train, y_train, epochs=40, batch_size=128,validation_split=0.2,callbacks=callbacks_list,verbose=1)\n",
        "\n",
        "np.savez('drive/My Drive/history_fnn.npz',loss=history.history['loss'],val_loss=history.history['val_loss']\\\n",
        "         ,acc=history.history['acc'],val_acc=history.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 14.4773 - acc: 0.1018 - val_loss: 14.4499 - val_acc: 0.1035\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 2s 48us/step - loss: 14.4764 - acc: 0.1019 - val_loss: 14.4499 - val_acc: 0.1035\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 14.4764 - acc: 0.1019 - val_loss: 14.4499 - val_acc: 0.1035\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 14.4764 - acc: 0.1019 - val_loss: 14.4499 - val_acc: 0.1035\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 2s 50us/step - loss: 14.4764 - acc: 0.1019 - val_loss: 14.4499 - val_acc: 0.1035\n",
            "Epoch 6/40\n",
            "30336/48000 [=================>............] - ETA: 0s - loss: 14.5061 - acc: 0.1000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9c610082a12d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/history_fnn.npz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m         \u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "W_OMB0GZwiRr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the learning curves. To this end, we load the history that we previously saved."
      ]
    },
    {
      "metadata": {
        "id": "0tWaM2rzwi6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=np.load('drive/My Drive/history_fnn.npz')\n",
        "loss,val_loss,acc,val_acc=data['loss'],data['val_loss'],data['acc'],data['val_acc']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(10,5))\n",
        "\n",
        "ax=axes[0]\n",
        "ax.plot(loss,'.--',label='training')\n",
        "ax.plot(val_loss,'.--',label='validation')\n",
        "ax.set_title('Loss Function')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[1]\n",
        "ax.plot(acc,'.--',label='training')\n",
        "ax.plot(val_acc,'.--',label='validation')\n",
        "ax.set_title('Accuracy')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[2]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[20:],loss[20:],'.--',label='training')\n",
        "ax.plot(vepochs[20:],val_loss[20:],'.--',label='validation')\n",
        "ax.set_title('Zoom Loss')\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8wbbQ0Yw5J-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now want visualize the effect of the different layers on the original data from the test set. To this end, we first perform a PCA on the original data to visualize in a 2D plane the data.\n",
        "\n",
        "- use the PCA Function of [scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
      ]
    },
    {
      "metadata": {
        "id": "bi4LBtrmw5j0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "pca = PCA(n_components=2)\n",
        "x_original=pca.fit_transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XR6kmgVPgk-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now plot the training set in the two-dimensional plane."
      ]
    },
    {
      "metadata": {
        "id": "pYLkjggLgFDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8))\n",
        "\n",
        "im1=ax.scatter(x_original[:,0],x_original[:,1],c=y_test1,cmap='jet')\n",
        "ax.set_title('PCA on raw data')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.colorbar(im1,ax=ax);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDvU5cYXjJZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now perform the same analysis after passing through one of the layer."
      ]
    },
    {
      "metadata": {
        "id": "fZ-1iZnMjLw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This line should be put if the model has been previously trained\n",
        "#model.load_weights('drive/My Drive/weights.best.hdf5')\n",
        "\n",
        "#In get_layer(), you should insert the name of the layer you are interested in from model.summary()\n",
        "\n",
        "test_data=x_test\n",
        "test_label=y_test1\n",
        "\n",
        "layer1=Model(inputs=model.input,outputs=model.get_layer('dense_2').output)\n",
        "layer1=layer1.predict(test_data)\n",
        "\n",
        "xl1=pca.fit_transform(layer1)\n",
        "\n",
        "\n",
        "kmeans=KMeans(n_clusters=10)\n",
        "kmeans.fit(layer1)\n",
        "y_pred1=kmeans.predict(layer1)\n",
        "\n",
        "\n",
        "vchange=np.ones(10)*1000\n",
        "for i in np.arange(10):\n",
        "  vchange[i]=Counter(test_label[y_pred1==i]).most_common(1)[0][0]\n",
        "\n",
        "y_pred=np.copy(y_pred1)\n",
        "for i in np.arange(10):\n",
        "  y_pred[y_pred1==i]=vchange[i]\n",
        " \n",
        "print('accuracy score:',accuracy_score(test_label,y_pred))\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,5))\n",
        "\n",
        "ax=axes[0]\n",
        "im1=ax.scatter(xl1[:,0],xl1[:,1],c=test_label,cmap='jet')\n",
        "ax.set_title('PCA with real labels')\n",
        "\n",
        "\n",
        "ax=axes[1]\n",
        "im2=ax.scatter(xl1[:,0],xl1[:,1],c=y_pred,cmap='jet')\n",
        "ax.set_title('PCA with k_means predicition')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.colorbar(im2,ax=axes.ravel().tolist());"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cQi8EzM7lbsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Convolutional neural networks\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "UEWWeEt9ls1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now focus on the classification of the MNIST dataset with convolutional neural networks. To this end, we construct a CNN with 3 convolutional layers (each of them accompanied by max Pooling layer) and two fully connected neural networks.\n",
        "\n",
        "Have a look at:\n",
        "- [CNN definition in keras](https://keras.io/layers/convolutional/)\n",
        "- [pooling layers in keras ](https://keras.io/layers/pooling/)"
      ]
    },
    {
      "metadata": {
        "id": "xbLvAAdRliVX",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(16, (3, 3), activation='relu', padding='same',input_shape=(28, 28, 1)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128, activation='relu'))\n",
        "cnn.add(Dense(10, activation='relu'))\n",
        "cnn.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eIDoDuA8Smr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice, that due to the nature of the convolutional filters, the numbers of parameters has decreased a lot. Nevertheless, as we will see this kind of architecture gives much better results on images.\n",
        "For the training, we have to reshape the data for the keras standard (for the tensorflow backend)"
      ]
    },
    {
      "metadata": {
        "id": "2Z2j-Lfll9iE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOmzWj928X_q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then train the model."
      ]
    },
    {
      "metadata": {
        "id": "Aduuths_8XOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This line should be put if the model has been previously trained\n",
        "#model.load_weights('drive/My Drive/weights.best.hdf5')\n",
        "# checkpoint\n",
        "filepath=\"drive/My Drive/weights_cnn.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "\n",
        "history=cnn.fit(x_train, y_train, epochs=10, batch_size=64,validation_split=0.2,callbacks=callbacks_list,verbose=1)\n",
        "\n",
        "np.savez('drive/My Drive/history_cnn.npz',loss=history.history['loss'],val_loss=history.history['val_loss']\\\n",
        "         ,acc=history.history['acc'],val_acc=history.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtmCAtlv8c4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then plot the loss function and the accuracy. Surprisingly, after a few number of epochs, the training converges to an accuracy of 98%! This is much better than with the FNN."
      ]
    },
    {
      "metadata": {
        "id": "_Akv9XfI8dRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=np.load('drive/My Drive/history_cnn.npz')\n",
        "loss,val_loss,acc,val_acc=data['loss'],data['val_loss'],data['acc'],data['val_acc']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4,figsize=(20,5))\n",
        "\n",
        "ax=axes[0]\n",
        "ax.plot(loss,'.--',label='training')\n",
        "ax.plot(val_loss,'.--',label='validation')\n",
        "ax.set_title('Loss Function')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[1]\n",
        "ax.plot(acc,'.--',label='training')\n",
        "ax.plot(val_acc,'.--',label='validation')\n",
        "ax.set_title('Accuracy')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[2]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],acc[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_acc[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Accuracy')\n",
        "ax.legend();\n",
        "\n",
        "ax=axes[3]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],loss[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_loss[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Loss')\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBmTIsqAIxL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also study the layer before the classfication with PCA and k-means.\n",
        "\n",
        "Choose a convolutional layer output and perform the PCA dimension reduction."
      ]
    },
    {
      "metadata": {
        "id": "mMUTCPFqIxjH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "pca = PCA(n_components=2)\n",
        "layer1=Model(inputs=cnn.input,outputs=cnn.get_layer('dense_6').output)\n",
        "layer1=layer1.predict(x_test)\n",
        "\n",
        "\n",
        "# Uncomment these lines to flatten the data coming from the CNN\n",
        "#s=layer1.shape\n",
        "#n1=s[1]*s[2]*s[3]\n",
        "#layer1=layer1.reshape(s[0],n1)\n",
        "\n",
        "xl1=pca.fit_transform(layer1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1YQyGtzJcHJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now plot the two-dimensional space and perform a k-means analysis."
      ]
    },
    {
      "metadata": {
        "id": "oMQDXu8FJZAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kmeans=KMeans(n_clusters=10)\n",
        "kmeans.fit(layer1)\n",
        "y_pred1=kmeans.predict(layer1)\n",
        "\n",
        "\n",
        "vchange=np.ones(10)*1000\n",
        "for i in np.arange(10):\n",
        "  vchange[i]=Counter(y_test1[y_pred1==i]).most_common(1)[0][0]\n",
        "\n",
        "y_pred=np.copy(y_pred1)\n",
        "for i in np.arange(10):\n",
        "  y_pred[y_pred1==i]=vchange[i]\n",
        " \n",
        "print('accuracy score:',accuracy_score(y_test1,y_pred))\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,5))\n",
        "\n",
        "ax=axes[0]\n",
        "im1=ax.scatter(xl1[:,0],xl1[:,1],c=y_test1,cmap='jet')\n",
        "ax.set_title('PCA with real labels')\n",
        "\n",
        "\n",
        "ax=axes[1]\n",
        "im2=ax.scatter(xl1[:,0],xl1[:,1],c=y_pred,cmap='jet')\n",
        "ax.set_title('PCA with k_means predicition')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig.colorbar(im2,ax=axes.ravel().tolist());"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XX7bvWBPXox8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch Normalization\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "Kz6g68WIXvTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then probe the same model but with a batch normalization layer after each convolutional layer."
      ]
    },
    {
      "metadata": {
        "id": "3ozx64uNYThu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQ8I6dTSYQ7Z",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "cnnb=Sequential()\n",
        "cnnb.add(Conv2D(16, (3, 3), activation='relu', padding='same',input_shape=(28, 28, 1)))\n",
        "cnnb.add(BatchNormalization())\n",
        "cnnb.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnnb.add(BatchNormalization())\n",
        "cnnb.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnnb.add(BatchNormalization())\n",
        "cnnb.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb.add(Flatten())\n",
        "cnnb.add(Dense(128, activation='relu'))\n",
        "cnnb.add(Dense(10, activation='relu'))\n",
        "cnnb.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "cnnb.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "cnnb.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivYNmWiYYdKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This line should be put if the model has been previously trained\n",
        "#model.load_weights('drive/My Drive/weights.best.hdf5')\n",
        "# checkpoint\n",
        "filepath=\"drive/My Drive/weights_cnnb.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "\n",
        "history=cnnb.fit(x_train, y_train, epochs=10, batch_size=64,validation_split=0.2,callbacks=callbacks_list,verbose=1)\n",
        "\n",
        "np.savez('drive/My Drive/history_cnnb.npz',loss=history.history['loss'],val_loss=history.history['val_loss']\\\n",
        "         ,acc=history.history['acc'],val_acc=history.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MRKlmpaYgQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=np.load('drive/My Drive/history_cnnb.npz')\n",
        "loss,val_loss,acc,val_acc=data['loss'],data['val_loss'],data['acc'],data['val_acc']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4,figsize=(20,5))\n",
        "\n",
        "ax=axes[0]\n",
        "ax.plot(loss,'.--',label='training')\n",
        "ax.plot(val_loss,'.--',label='validation')\n",
        "ax.set_title('Loss Function')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[1]\n",
        "ax.plot(acc,'.--',label='training')\n",
        "ax.plot(val_acc,'.--',label='validation')\n",
        "ax.set_title('Accuracy')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[2]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],acc[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_acc[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Accuracy')\n",
        "ax.legend();\n",
        "\n",
        "ax=axes[3]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],loss[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_loss[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Loss')\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "68er9bBqYkZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing the effects of the filters\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "KDojKeXdYwJ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now look at the effect of the convolutional filters on the image."
      ]
    },
    {
      "metadata": {
        "id": "fFfxaSJsYpCw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We take 12 examples in the training set\n",
        "nexample=12\n",
        "mask=np.random.randint(x_train.shape[0],size=nexample)\n",
        "\n",
        "fig,axes=plt.subplots(nrows=7,ncols=nexample,figsize=(20,10))\n",
        "\n",
        "layer1=Model(inputs=cnnb.input,outputs=cnnb.get_layer('conv2d_13').output)\n",
        "layer1=layer1.predict(x_train[mask,:,:,:])\n",
        "\n",
        "layer2=Model(inputs=cnnb.input,outputs=cnnb.get_layer('conv2d_14').output)\n",
        "layer2=layer2.predict(x_train[mask,:,:,:])\n",
        "\n",
        "layer3=Model(inputs=cnnb.input,outputs=cnnb.get_layer('conv2d_15').output)\n",
        "layer3=layer3.predict(x_train[mask,:,:,:])\n",
        "\n",
        "mat=[x_train1[mask],layer1[:,:,:,0],layer1[:,:,:,1],layer2[:,:,:,0],layer2[:,:,:,1],layer3[:,:,:,1],layer3[:,:,:,0]]\n",
        "\n",
        "ll=['original','layer1','layer1','layer2','layer2','layer3','layer3']\n",
        "\n",
        "for j in np.arange(7):\n",
        "  im=mat[j]\n",
        "  l=ll[j]\n",
        "  for i in np.arange(nexample):\n",
        "    ax=axes[j,i]\n",
        "    ax.imshow(im[i,:,:],cmap='gray_r')\n",
        "    if i==2:\n",
        "      ax.set_title(l)\n",
        "    ax.axis('off')\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AD0jkQf1Y0le",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "QoAhR7vTY66L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To avoid overfitting, people developped the data augmentation technique. In the latter,one generates from the training set new images that are rotated, squeezed, translated, deformed... These images are then used as a bigger training set.\n",
        "The data aumentation is implemented keras. We first train an image generator from our training set."
      ]
    },
    {
      "metadata": {
        "id": "7RBz1Cx2Y8m5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Solution (double click to see the code)\n",
        "train_generator = ImageDataGenerator( rotation_range=30, \n",
        "                 width_shift_range=0.2, height_shift_range=0.2) \n",
        "\n",
        "# separate the training and the validation set\n",
        "\n",
        "x_train, x_validation, y_train1, y_validation1 = train_test_split(x_train, y_train1, test_size=0.2)\n",
        "y_train = np_utils.to_categorical(y_train1, n_classes)\n",
        "y_validation = np_utils.to_categorical(y_validation1, n_classes)\n",
        "\n",
        "train_generator.fit(x_train, augment=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V4hMz039ZGwo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can have a look at the different examples produced by the generator. The original image is shwon in the top left corner."
      ]
    },
    {
      "metadata": {
        "id": "3Dhp65cpZGH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i=np.random.randint(x_train.shape[0])\n",
        "\n",
        "x=x_train[i,:,:,:]\n",
        "print('label:',y_train1[i])\n",
        "\n",
        "plt.subplot(3,4,1)\n",
        "plt.imshow(x_train[i,:,:,0])\n",
        "plt.title('original')\n",
        "plt.axis('off')\n",
        "\n",
        "for j in np.arange(2,11):\n",
        "  augmented_images,_=next( train_generator.flow( x.reshape(1,28,28,1),y=[1], batch_size=1))\n",
        "  plt.subplot(3,4,j)\n",
        "  plt.imshow(augmented_images[0,:,:,0])\n",
        "  plt.axis('off')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QAW2Ne07ZSmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now reuse the architecture in the previous chapter"
      ]
    },
    {
      "metadata": {
        "id": "ohko76bQZTAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnnb_augm=Sequential()\n",
        "cnnb_augm.add(Conv2D(16, (3, 3), activation='relu', padding='same',input_shape=(28, 28, 1)))\n",
        "cnnb_augm.add(BatchNormalization())\n",
        "cnnb_augm.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb_augm.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnnb_augm.add(BatchNormalization())\n",
        "cnnb_augm.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb_augm.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "cnnb_augm.add(BatchNormalization())\n",
        "cnnb_augm.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnb_augm.add(Flatten())\n",
        "cnnb_augm.add(Dense(128, activation='relu'))\n",
        "cnnb_augm.add(Dense(10, activation='relu'))\n",
        "cnnb_augm.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "cnnb_augm.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "cnnb_augm.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "miRNlu5cZoIQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We train it on the augmented data."
      ]
    },
    {
      "metadata": {
        "id": "BtEcplkBZl_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights('drive/My Drive/weights.best_augmented.hdf5')\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"drive/My Drive/weights.best_cnnb_augm.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "batch_size=64\n",
        "epochs=40\n",
        "history=cnnb_augm.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size),\n",
        "          steps_per_epoch=  x_train.shape[0]//batch_size,validation_data=(x_validation, y_validation),\n",
        "          epochs=epochs,callbacks=callbacks_list)\n",
        "\n",
        "np.savez('drive/My Drive/history_cnnb_augm.npz',loss=history.history['loss'],val_loss=history.history['val_loss']\\\n",
        "         ,acc=history.history['acc'],val_acc=history.history['val_acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UkGv3_4ZsgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=np.load('drive/My Drive/history_cnnb_augm.npz')\n",
        "loss,val_loss,acc,val_acc=data['loss'],data['val_loss'],data['acc'],data['val_acc']\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4,figsize=(20,5))\n",
        "\n",
        "ax=axes[0]\n",
        "ax.plot(loss,'.--',label='training')\n",
        "ax.plot(val_loss,'.--',label='validation')\n",
        "ax.set_title('Loss Function')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[1]\n",
        "ax.plot(acc,'.--',label='training')\n",
        "ax.plot(val_acc,'.--',label='validation')\n",
        "ax.set_title('Accuracy')\n",
        "ax.legend()\n",
        "\n",
        "ax=axes[2]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],acc[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_acc[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Accuracy')\n",
        "ax.legend();\n",
        "\n",
        "ax=axes[3]\n",
        "vepochs=np.arange(np.size(loss))\n",
        "ax.plot(vepochs[5:],loss[5:],'.--',label='training')\n",
        "ax.plot(vepochs[5:],val_loss[5:],'.--',label='validation')\n",
        "ax.set_title('Zoom Loss')\n",
        "ax.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}